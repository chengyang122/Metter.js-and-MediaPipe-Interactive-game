{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chengyang122/Metter.js-and-MediaPipe-Interactive-game/blob/main/Detectron2BarcodeMaskR-CNN50_FPN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWispC-Tw25i",
        "outputId": "ac50bc08-96f5-4a30-9a5a-7ec016d78316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "p3VYeFqXzogi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQclDaJ_vmsA"
      },
      "outputs": [],
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5yPG0bI5HwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e050a739-8b83-4bf8-abe8-db361a224bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.88 ms (started: 2022-05-23 04:38:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "import cv2\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "from tqdm import tqdm\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.structures import BoxMode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#please use my shared file, set a shortcut, all image files are in Anaya.zip (Unzipped Files)\n",
        "\n",
        "img_address_base = '/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/'\n",
        "df1 = pd.read_excel('/content/drive/MyDrive/barcode/AnanyaAnnotation_10-09-2017.xlsx')\n",
        "df2 = pd.read_excel('/content/drive/MyDrive/barcode/Christian_annotations_2017-10-09.xlsx', header=None)\n",
        "df2.columns = df1.columns\n",
        "df2['Image Filename'] = df2['Image Filename'].str[:-4]\n",
        "\n",
        "\n",
        "frames = [df1, df2]\n",
        "df = pd.concat(frames, ignore_index=True)\n",
        "img = cv2.imread(img_address_base + df.loc[1][0] + '.jpg')\n",
        "df['isBarcode'] = 1\n",
        "df['ymax'] = df[['Y1','Y2', 'Y3', 'Y4']].max(axis=1)\n",
        "df['ymin'] = df[['Y1','Y2', 'Y3', 'Y4']].min(axis=1)\n",
        "df['xmax'] = df[['X1','X2','X3','X4']].max(axis=1)\n",
        "df['xmin'] = df[['X1','X2','X3','X4']].min(axis=1)\n",
        "df['width'] = img.shape[1] #since all shape are the same. Can use shape of one picture \n",
        "df['height'] = img.shape[0] #since all shape are the same. Can use shape of one picture \n",
        "df['class'] = 1\n",
        "df['filename'] = df['Image Filename']+ '.jpg'\n",
        "df[\"category_id\"] = 0\n",
        "\n",
        "image_names = df.loc[:, 'Image Filename'].unique()\n",
        "np.random.seed(seed=0)\n",
        "np.random.shuffle(image_names)\n",
        "test = image_names[:20]\n",
        "validation = image_names[20:30]\n",
        "train = image_names[30:]\n",
        "\n",
        "test_df = df[df['Image Filename'].isin(test)]\n",
        "validation_df = df[df['Image Filename'].isin(validation)]\n",
        "train_df = df[df['Image Filename'].isin(train)]\n",
        "\n",
        "img_address_base = '/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/'\n",
        "img = cv2.imread(img_address_base + train_df.loc[1][0] + '.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8T9WQ0fzwt5",
        "outputId": "7f0738e1-01ae-45c9-a78b-9688c83d7000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 746 ms (started: 2022-05-23 04:05:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySHx9KLls_kB",
        "outputId": "0e43689c-06e4-41cc-ec64-6f2ae45205cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 69 ms (started: 2022-05-23 04:05:42 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "#show the shape of the output image \n",
        "def annotation(row):\n",
        "    annotation = {}\n",
        "    area = (row.xmax -row.xmin)*(row.ymax - row.ymin)\n",
        "    annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax -row.xmin,row.ymax-row.ymin ]\n",
        "    annotation['bbox_mode'] = 1\n",
        "    annotation[\"category_id\"] = row.category_id\n",
        "    annotation[\"segmentation\"] = [[row.X1, row.Y1, row.X2, row.Y2, row.X3, row.Y3, row.X4, row.Y4]]\n",
        "    return annotation\n",
        "\n",
        "dftrain = train_df\n",
        "dftest = test_df\n",
        "\n",
        "annotation_column = []\n",
        "for row in dftrain.itertuples():\n",
        "    annotation_column.append(annotation(row))\n",
        "dftrain['annotation'] = annotation_column\n",
        "g = dftrain[['Image Filename', 'annotation']].groupby('Image Filename')['annotation'].apply(list).reset_index(name='annotations')\n",
        "g.columns = ['file_name','annotations']\n",
        "g['width'] = 2592\n",
        "g['height'] = 1944\n",
        "g['image_id'] = np.arange(len(g))\n",
        "g.index=np.arange(len(g))\n",
        "g.reset_index(inplace=True)\n",
        "g.to_json(\"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/train_dataset.json\",orient=\"records\")\n",
        "\n",
        "annotation_column = []\n",
        "for row in dftest.itertuples():\n",
        "    annotation_column.append(annotation(row))\n",
        "dftest['annotation'] = annotation_column\n",
        "g = dftest[['Image Filename', 'annotation']].groupby('Image Filename')['annotation'].apply(list).reset_index(name='annotations')\n",
        "g.columns = ['file_name','annotations']\n",
        "g['width'] = 2592\n",
        "g['height'] = 1944\n",
        "g['image_id'] = np.arange(len(g))\n",
        "g.index=np.arange(len(g))\n",
        "g.reset_index(inplace=True)\n",
        "g.to_json(\"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/test_dataset.json\",orient=\"records\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3m5rpnr3HIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594d29a1-4c48-4be5-8508-3aaed3ca0fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16.9 ms (started: 2022-05-23 04:06:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_board_dicts_train():#/test_dataset.json #/train_dataset.json\n",
        "    json_file = \"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)\"+ '/train_dataset.json' #Fetch the json file\n",
        "    with open(json_file) as f:\n",
        "        dataset_dicts = json.load(f)\n",
        "    for i in dataset_dicts:\n",
        "        filename = i[\"file_name\"] \n",
        "        i[\"file_name\"] = \"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)\"+\"/\"+filename +'.jpg' \n",
        "        for j in i[\"annotations\"]:\n",
        "            j[\"bbox_mode\"] = BoxMode.XYWH_ABS #Setting the required Box Mode\n",
        "            j[\"category_id\"] = int(j[\"category_id\"])\n",
        "    return dataset_dicts\n",
        "\n",
        "def get_board_dicts_test():#/test_dataset.json #/train_dataset.json\n",
        "    json_file = \"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)\"+ '/test_dataset.json' #Fetch the json file\n",
        "    with open(json_file) as f:\n",
        "        dataset_dicts = json.load(f)\n",
        "    for i in dataset_dicts:\n",
        "        filename = i[\"file_name\"] \n",
        "        i[\"file_name\"] = \"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)\"+\"/\"+filename +'.jpg' \n",
        "        for j in i[\"annotations\"]:\n",
        "            j[\"bbox_mode\"] = BoxMode.XYWH_ABS #Setting the required Box Mode\n",
        "            j[\"category_id\"] = int(j[\"category_id\"])\n",
        "    return dataset_dicts\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "DatasetCatalog.clear()\n",
        "#Registering the Dataset\n",
        "DatasetCatalog.register(\"boardetect_train\", get_board_dicts_train)\n",
        "MetadataCatalog.get(\"boardetect_train\").set(thing_classes=[\"Barcode\"])\n",
        "\n",
        "DatasetCatalog.register(\"boardetect_test\", get_board_dicts_test)\n",
        "MetadataCatalog.get(\"boardetect_test\").set(thing_classes=[\"Barcode\"])\n",
        "\n",
        "board_metadata_train = MetadataCatalog.get(\"boardetect_train\")\n",
        "board_metadata_test = MetadataCatalog.get(\"boardetect_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHEkmWoH3MoJ"
      },
      "outputs": [],
      "source": [
        "dataset_dicts = get_board_dicts_train()\n",
        "#Randomly choosing 3 images from the Set\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    print(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=board_metadata_train)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7ZEYQQ7yj9V"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"boardetect_train\",)\n",
        "cfg.DATASETS.TEST = (\"boardetect_test\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9 # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"boardetect_test\", )\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_board_dicts_test()\n",
        "decresult = 0\n",
        "for d in random.sample(dataset_dicts, 46):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=board_metadata_test, \n",
        "                   scale=0.8,\n",
        "                   instance_mode=ColorMode.IMAGE   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    decresult = decresult + len(outputs['instances'])"
      ],
      "metadata": {
        "id": "gNxkEECQ0Xh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd614023-ef6d-49ed-9faf-ad7a5ab5b7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 17 s (started: 2022-05-23 02:28:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dicts"
      ],
      "metadata": {
        "id": "7gHnKJI2IO4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk4R3pbVAdg2"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9 # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"boardetect_test\", )\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_board_dicts_test()\n",
        "decresult = 0\n",
        "for d in random.sample(dataset_dicts, 10):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=board_metadata_test, \n",
        "                   scale=0.8,\n",
        "                   instance_mode=ColorMode.IMAGE   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    decresult = decresult + len(outputs['instances'])\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "print(f'number of detected boxes is {decresult}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6cXeXUu7e5U"
      },
      "outputs": [],
      "source": [
        "im = cv2.imread('/content/drive/MyDrive/barcode/capture_2018_08_08_05_30_52.png')\n",
        "outputs = predictor(im)\n",
        "v = Visualizer(im[:, :, ::-1],\n",
        "                metadata=board_metadata_test, \n",
        "                scale=0.8,\n",
        "                instance_mode=ColorMode.IMAGE   # remove the colors of unsegmented pixels\n",
        ")\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[\"instances\"].scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEB_90e6KqRn",
        "outputId": "37ea5ff2-6eb4-4348-c5ce-c60ad02af1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9953, 0.9947, 0.9933, 0.9921, 0.9837, 0.9788, 0.9763, 0.9586],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.17 ms (started: 2022-05-23 04:36:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateIoU(contour1, contour2):\n",
        "    # Two separate contours trying to check intersection on\n",
        "    contours = [contour1, contour2]\n",
        "\n",
        "    # Create image filled with zeros the same size of original image\n",
        "    blank = np.zeros([1944, 2592]) \n",
        "\n",
        "    # Copy each contour into its own image and fill it with '1'\n",
        "    image1 = cv2.drawContours(blank.copy(), contours, 0, 1, thickness=cv2.FILLED)\n",
        "    image2 = cv2.drawContours(blank.copy(), contours, 1, 1, thickness=cv2.FILLED)\n",
        "\n",
        "\n",
        "    area1 = cv2.contourArea(contour1)\n",
        "    area2 = cv2.contourArea(contour2)\n",
        "    intersection = np.logical_and(image1, image2)\n",
        "    contours, hierarchy = cv2.findContours(intersection.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return 0\n",
        "    common_area = cv2.contourArea(contours[0])\n",
        "    IoU = common_area/(area1+area2-common_area)\n",
        "    # Use the logical AND operation on the two images\n",
        "    # Since the two images had bitwise and applied to it,\n",
        "    # there should be a '1' or 'True' where there was intersection\n",
        "    # and a '0' or 'False' where it didnt intersect\n",
        "    # Check if there was a '1' in the intersection\n",
        "    return IoU\n",
        "\n",
        "\n",
        "def truePositive(predicted_box, true_box):\n",
        "    sum_IoU = 0\n",
        "    hit_count = 0\n",
        "    for conpred in predicted_box:\n",
        "      hit = 0\n",
        "      for contrue in true_box:\n",
        "        IoU = calculateIoU(conpred, contrue)\n",
        "        if IoU>0.6:\n",
        "          hit =  1\n",
        "          sum_IoU = sum_IoU+IoU\n",
        "      if hit == 1:\n",
        "        hit_count = hit_count + 1\n",
        "    if hit_count == 0:\n",
        "      return 0, None\n",
        "    ave_IoU = sum_IoU/hit_count    \n",
        "    return hit_count, ave_IoU\n",
        "\n",
        "def collect_annotation(dataframe):\n",
        "  true_box = []\n",
        "  for i in range(len(dataframe)):\n",
        "    rec1 = dataframe.iloc[i, :]\n",
        "    contour = np.array([[rec1.X1,rec1.Y1],[rec1.X2,rec1.Y2],[rec1.X3,rec1.Y3], [rec1.X4,rec1.Y4]], dtype=np.int32)\n",
        "    true_box.append(contour)\n",
        "  return true_box\n",
        "\n",
        "\n",
        "def collect_predicted(result):\n",
        "  Object, Mask = result\n",
        "  useful_index = []\n",
        "  for i in range(len(Object)):\n",
        "    score = Object[i]\n",
        "    if score > 0.6:\n",
        "      useful_index.append(i)\n",
        "\n",
        "  predicted_box = []\n",
        "  predicted_contour = []\n",
        "  for index in useful_index:\n",
        "    mg = Mask[index].cpu().numpy().astype(np.uint8)\n",
        "    contours, hierarchy = cv2.findContours(mg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt = contours[0]\n",
        "    rect = cv2.minAreaRect(cnt)\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.int0(box)\n",
        "    predicted_box.append(box)\n",
        "    predicted_contour.append(cnt)\n",
        "  return predicted_box, predicted_contour"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqU_ti1DMASm",
        "outputId": "605935c7-a2db-4cb4-b3ae-3e47683d58f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 60.5 ms (started: 2022-05-23 04:41:25 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Color'] = test_df['Color'].str.strip()\n",
        "image_name = test_df.loc[:, 'Image Filename'].unique() # get unique item in one column \n",
        "img_address_base = '/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/'\n",
        "misimage = []\n",
        "\n",
        "sum_hitR = 0\n",
        "sum_hitG = 0\n",
        "sum_hitB = 0\n",
        "\n",
        "pred_total = 0\n",
        "\n",
        "sum_R = 0\n",
        "sum_G = 0\n",
        "sum_B = 0\n",
        "for i in tqdm(range(len(image_name))):\n",
        "  df2 = df[df.loc[:, 'Image Filename']==image_name[i]] # choose data of one image \n",
        "  imgAddress = img_address_base + image_name[i] + '.jpg'  \n",
        "  img = cv2.imread(imgAddress)\n",
        "  output = predictor(img)\n",
        "  result = (output[\"instances\"].scores, output[\"instances\"].pred_masks)\n",
        "  predicted_box, predicted_contour = collect_predicted(result)\n",
        "  dfR = df2[df2.loc[:, 'Color'] == 'R']\n",
        "  dfG = df2[df2.loc[:, 'Color'] == 'G']\n",
        "  dfB = df2[df2.loc[:, 'Color'] == 'B']\n",
        "  true_box = collect_annotation(df2)\n",
        "  true_boxR = collect_annotation(dfR)\n",
        "  true_boxG = collect_annotation(dfG)\n",
        "  true_boxB = collect_annotation(dfB)\n",
        "  #hit, IoU = truePositive(predicted_box, true_box)\n",
        "  hitR, IoR = truePositive(predicted_box, true_boxR)\n",
        "  hitG, IoG = truePositive(predicted_box, true_boxG)\n",
        "  hitB, IoB = truePositive(predicted_box, true_boxB)\n",
        "\n",
        "  sum_hitR += hitR\n",
        "  sum_hitG += hitG\n",
        "  sum_hitB += hitB\n",
        "\n",
        "  sum_R += len(true_boxR) \n",
        "  sum_G += len(true_boxG) \n",
        "  sum_B += len(true_boxB) \n",
        "\n",
        "  pred_total += len(predicted_box)\n",
        "\n",
        "  sum_hit = hitR + hitB + hitG\n",
        "  sum_all = len(true_boxR)  + len(true_boxG) + len(true_boxB) \n",
        "  if sum_hit!=sum_all:\n",
        "    img = cv2.imread(imgAddress)\n",
        "    cv2.drawContours(img, predicted_box, -1 ,(0,255,0),2) # predicted result is green\n",
        "    cv2.drawContours(img, true_box, -1, (255,0,0), 2) # annotated result is blue \n",
        "    cv2.drawContours(img, predicted_contour, -1,(0,0,255),2) # the predicted contour is red\n",
        "    cv2_imshow(img)\n",
        "    print(f'number of R mishit is {len(true_boxR) - hitR}')\n",
        "    print(f'number of G mishit is {len(true_boxG) - hitG}')\n",
        "    print(f'number of B mishit is {len(true_boxB) - hitB}')"
      ],
      "metadata": {
        "id": "W-MIX8GjLRyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The accuracy of the algorithm is\n",
        "(sum_hitR + sum_hitG + sum_hitB)/(sum_R + sum_G + sum_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4jtvX_FQMuC",
        "outputId": "f12afb7f-774c-45db-987a-7a3dd338a1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9124087591240876"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.91 ms (started: 2022-05-23 04:50:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TP_all = sum_hitR + sum_hitG + sum_hitB\n",
        "TP_R = sum_hitR\n",
        "TP_G = sum_hitG\n",
        "TP_B = sum_hitB\n",
        "\n",
        "FN_all = sum_R + sum_G + sum_B - sum_hitR - sum_hitG - sum_hitB \n",
        "FN_R = sum_R - sum_hitR\n",
        "FN_G = sum_G - sum_hitG\n",
        "FN_B = sum_B - sum_hitB\n",
        "\n",
        "#since for a mis predicted, it can not be count into R or G or B. So we just assume all three of them get an average false Positive \n",
        "FP = pred_total - sum_hitR - sum_hitG - sum_hitB \n",
        "\n",
        "# TN can not be calcuated \n",
        "\n",
        "F1_all = 2*TP_all/(2*TP_all+FN_all+FP)\n",
        "F1_R = 2*TP_R/(2*TP_R+FN_R+FP/3)\n",
        "F1_G = 2*TP_G/(2*TP_G+FN_G+FP/3)\n",
        "F1_B = 2*TP_B/(2*TP_B+FN_B+FP/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg1667KoWubP",
        "outputId": "dbd917a2-4696-4af2-90b2-4c292b082151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.02 ms (started: 2022-05-23 05:43:29 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Report for Detectron 2 model with mask_rcnn_R_50_FPN_3x')\n",
        "print(f'for all data TP is {TP_all}, FN is {FN_all}, FP is {FP}, TN can not be calculated, the F1 score is {F1_all:.2f}')\n",
        "print(f'for R data TP is {TP_R}, FN is {FN_R}, FP is {FP}, TN can not be calculated, the F1 score is {F1_R:.2f}')\n",
        "print(f'for G data TP is {TP_G}, FN is {FN_G}, FP is {FP}, TN can not be calculated, the F1 score is {F1_G:.2f}')\n",
        "print(f'for B data TP is {TP_B}, FN is {FN_B}, FP is {FP}, TN can not be calculated, the F1 score is {F1_B:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOjz0pBxbJNR",
        "outputId": "a58f8aab-4699-4189-dc45-cf6a3e09b986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for all data TP is 125, FN is 12, FP is 14, TN can not be calculated, the F1 score is 0.91\n",
            "for R data TP is 77, FN is 2, FP is 14, TN can not be calculated, the F1 score is 0.96\n",
            "for G data TP is 34, FN is 3, FP is 14, TN can not be calculated, the F1 score is 0.90\n",
            "for B data TP is 14, FN is 7, FP is 14, TN can not be calculated, the F1 score is 0.71\n",
            "time: 2.07 ms (started: 2022-05-23 05:43:31 +00:00)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Detectron2BarcodeIdentificationPlus.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdUXmgdF64VRG9Dxav6R6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}