{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chengyang122/Metter.js-and-MediaPipe-Interactive-game/blob/main/Detectron2BarcodeSwinTR-CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWispC-Tw25i",
        "outputId": "91c23118-ffcd-470c-bc70-7fe406935773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "p3VYeFqXzogi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8c27a7-d16b-4435-87c3-e609ae3e634a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "time: 192 Âµs (started: 2022-05-23 09:08:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eQclDaJ_vmsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f8a1c8-b6e6-4998-8177-932a31bea008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n",
            "torch:  1.11 ; cuda:  cu113\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-t_ke4er3\n",
            "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-t_ke4er3\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.8.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.1.5.post20220512)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: omegaconf<=2.2.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.1.2)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.2)\n",
            "Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (21.4b2)\n",
            "Requirement already satisfied: scipy>1.5.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.7.3)\n",
            "Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (7.1.2)\n",
            "Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (4.2.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (0.10.2)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (2022.4.24)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\n",
            "Requirement already satisfied: importlib-resources<5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.2.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.8)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources<5.3->hydra-core>=1.1->detectron2==0.6) (3.8.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.46.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (4.11.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.0)\n",
            "time: 14.2 s (started: 2022-05-23 09:08:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "id": "ORLVkItKSfSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z5yPG0bI5HwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df341866-97ff-4980-fa39-a31aa08e86d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.04 s (started: 2022-05-23 09:08:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "import cv2\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "from tqdm import tqdm\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.structures import BoxMode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#please use my shared file, set a shortcut, all image files are in Anaya.zip (Unzipped Files)\n",
        "\n",
        "img_address_base = '/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/'\n",
        "df1 = pd.read_excel('/content/drive/MyDrive/barcode/AnanyaAnnotation_10-09-2017.xlsx')\n",
        "df2 = pd.read_excel('/content/drive/MyDrive/barcode/Christian_annotations_2017-10-09.xlsx', header=None)\n",
        "df2.columns = df1.columns\n",
        "df2['Image Filename'] = df2['Image Filename'].str[:-4]\n",
        "\n",
        "\n",
        "frames = [df1, df2]\n",
        "df = pd.concat(frames, ignore_index=True)\n",
        "img = cv2.imread(img_address_base + df.loc[1][0] + '.jpg')\n",
        "df['isBarcode'] = 1\n",
        "df['ymax'] = df[['Y1','Y2', 'Y3', 'Y4']].max(axis=1)\n",
        "df['ymin'] = df[['Y1','Y2', 'Y3', 'Y4']].min(axis=1)\n",
        "df['xmax'] = df[['X1','X2','X3','X4']].max(axis=1)\n",
        "df['xmin'] = df[['X1','X2','X3','X4']].min(axis=1)\n",
        "df['width'] = img.shape[1] #since all shape are the same. Can use shape of one picture \n",
        "df['height'] = img.shape[0] #since all shape are the same. Can use shape of one picture \n",
        "df['class'] = 1\n",
        "df['filename'] = df['Image Filename']+ '.jpg'\n",
        "df[\"category_id\"] = 0\n",
        "\n",
        "image_names = df.loc[:, 'Image Filename'].unique()\n",
        "np.random.seed(seed=0)\n",
        "np.random.shuffle(image_names)\n",
        "test = image_names[:20]\n",
        "validation = image_names[20:30]\n",
        "train = image_names[30:]\n",
        "\n",
        "test_df = df[df['Image Filename'].isin(test)]\n",
        "validation_df = df[df['Image Filename'].isin(validation)]\n",
        "train_df = df[df['Image Filename'].isin(train)]\n",
        "\n",
        "img_address_base = '/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/'\n",
        "img = cv2.imread(img_address_base + train_df.loc[1][0] + '.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8T9WQ0fzwt5",
        "outputId": "270007c3-b6e3-46cb-938c-44f0c098b1c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.23 s (started: 2022-05-23 09:10:07 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySHx9KLls_kB",
        "outputId": "ebb47e28-fcbf-4028-f162-71146959de57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 74.6 ms (started: 2022-05-23 09:10:11 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "#show the shape of the output image \n",
        "def annotation(row):\n",
        "    annotation = {}\n",
        "    area = (row.xmax -row.xmin)*(row.ymax - row.ymin)\n",
        "    annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax -row.xmin,row.ymax-row.ymin ]\n",
        "    annotation['bbox_mode'] = 1\n",
        "    annotation[\"category_id\"] = row.category_id\n",
        "    annotation[\"segmentation\"] = [[row.X1, row.Y1, row.X2, row.Y2, row.X3, row.Y3, row.X4, row.Y4]]\n",
        "    return annotation\n",
        "\n",
        "dftrain = train_df\n",
        "dftest = test_df\n",
        "\n",
        "annotation_column = []\n",
        "for row in dftrain.itertuples():\n",
        "    annotation_column.append(annotation(row))\n",
        "dftrain['annotation'] = annotation_column\n",
        "g = dftrain[['Image Filename', 'annotation']].groupby('Image Filename')['annotation'].apply(list).reset_index(name='annotations')\n",
        "g.columns = ['file_name','annotations']\n",
        "g['width'] = 2592\n",
        "g['height'] = 1944\n",
        "g['image_id'] = np.arange(len(g))\n",
        "g.index=np.arange(len(g))\n",
        "g.reset_index(inplace=True)\n",
        "g.to_json(\"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/train_dataset.json\",orient=\"records\")\n",
        "\n",
        "annotation_column = []\n",
        "for row in dftest.itertuples():\n",
        "    annotation_column.append(annotation(row))\n",
        "dftest['annotation'] = annotation_column\n",
        "g = dftest[['Image Filename', 'annotation']].groupby('Image Filename')['annotation'].apply(list).reset_index(name='annotations')\n",
        "g.columns = ['file_name','annotations']\n",
        "g['width'] = 2592\n",
        "g['height'] = 1944\n",
        "g['image_id'] = np.arange(len(g))\n",
        "g.index=np.arange(len(g))\n",
        "g.reset_index(inplace=True)\n",
        "g.to_json(\"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/test_dataset.json\",orient=\"records\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j3m5rpnr3HIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2d2796-0cdc-4368-87ff-7c6a65296f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 24.4 ms (started: 2022-05-23 09:10:23 +00:00)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_board_dicts_train():#/test_dataset.json #/train_dataset.json\n",
        "    json_file = \"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)\"+ '/train_dataset.json' #Fetch the json file\n",
        "    with open(json_file) as f:\n",
        "        dataset_dicts = json.load(f)\n",
        "    for i in dataset_dicts:\n",
        "        filename = i[\"file_name\"] \n",
        "        i[\"file_name\"] = \"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)\"+\"/\"+filename +'.jpg' \n",
        "        for j in i[\"annotations\"]:\n",
        "            j[\"bbox_mode\"] = BoxMode.XYWH_ABS #Setting the required Box Mode\n",
        "            j[\"category_id\"] = int(j[\"category_id\"])\n",
        "    return dataset_dicts\n",
        "\n",
        "def get_board_dicts_test():#/test_dataset.json #/train_dataset.json\n",
        "    json_file = \"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)\"+ '/test_dataset.json' #Fetch the json file\n",
        "    with open(json_file) as f:\n",
        "        dataset_dicts = json.load(f)\n",
        "    for i in dataset_dicts:\n",
        "        filename = i[\"file_name\"] \n",
        "        i[\"file_name\"] = \"/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)\"+\"/\"+filename +'.jpg' \n",
        "        for j in i[\"annotations\"]:\n",
        "            j[\"bbox_mode\"] = BoxMode.XYWH_ABS #Setting the required Box Mode\n",
        "            j[\"category_id\"] = int(j[\"category_id\"])\n",
        "    return dataset_dicts\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "DatasetCatalog.clear()\n",
        "#Registering the Dataset\n",
        "DatasetCatalog.register(\"boardetect_train\", get_board_dicts_train)\n",
        "MetadataCatalog.get(\"boardetect_train\").set(thing_classes=[\"Barcode\"])\n",
        "\n",
        "DatasetCatalog.register(\"boardetect_test\", get_board_dicts_test)\n",
        "MetadataCatalog.get(\"boardetect_test\").set(thing_classes=[\"Barcode\"])\n",
        "\n",
        "board_metadata_train = MetadataCatalog.get(\"boardetect_train\")\n",
        "board_metadata_test = MetadataCatalog.get(\"boardetect_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHEkmWoH3MoJ"
      },
      "outputs": [],
      "source": [
        "dataset_dicts = get_board_dicts_train()\n",
        "#Randomly choosing 3 images from the Set\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    print(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=board_metadata_train)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7ZEYQQ7yj9V"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "add_swint_config(cfg)\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/barcode/SwinT_detectron2-main/configs/SwinT/mask_rcnn_swint_T_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"boardetect_train\",)\n",
        "cfg.DATASETS.TEST = (\"boardetect_test\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS ='/content/drive/MyDrive/barcode/SwinT_detectron2-main/mask_rcnn_swint_T_coco17.pth'  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9 # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"boardetect_test\", )\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_board_dicts_test()\n",
        "decresult = 0\n",
        "for d in random.sample(dataset_dicts, 46):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=board_metadata_test, \n",
        "                   scale=0.8,\n",
        "                   instance_mode=ColorMode.IMAGE   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    decresult = decresult + len(outputs['instances'])"
      ],
      "metadata": {
        "id": "gNxkEECQ0Xh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd614023-ef6d-49ed-9faf-ad7a5ab5b7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 17 s (started: 2022-05-23 02:28:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dicts"
      ],
      "metadata": {
        "id": "7gHnKJI2IO4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk4R3pbVAdg2"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9 # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"boardetect_test\", )\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_board_dicts_test()\n",
        "decresult = 0\n",
        "for d in random.sample(dataset_dicts, 10):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=board_metadata_test, \n",
        "                   scale=0.8,\n",
        "                   instance_mode=ColorMode.IMAGE   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    decresult = decresult + len(outputs['instances'])\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "print(f'number of detected boxes is {decresult}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6cXeXUu7e5U"
      },
      "outputs": [],
      "source": [
        "im = cv2.imread('/content/drive/MyDrive/barcode/capture_2018_08_08_05_30_52.png')\n",
        "outputs = predictor(im)\n",
        "v = Visualizer(im[:, :, ::-1],\n",
        "                metadata=board_metadata_test, \n",
        "                scale=0.8,\n",
        "                instance_mode=ColorMode.IMAGE   # remove the colors of unsegmented pixels\n",
        ")\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateIoU(contour1, contour2):\n",
        "    # Two separate contours trying to check intersection on\n",
        "    contours = [contour1, contour2]\n",
        "\n",
        "    # Create image filled with zeros the same size of original image\n",
        "    blank = np.zeros([1944, 2592]) \n",
        "\n",
        "    # Copy each contour into its own image and fill it with '1'\n",
        "    image1 = cv2.drawContours(blank.copy(), contours, 0, 1, thickness=cv2.FILLED)\n",
        "    image2 = cv2.drawContours(blank.copy(), contours, 1, 1, thickness=cv2.FILLED)\n",
        "\n",
        "\n",
        "    area1 = cv2.contourArea(contour1)\n",
        "    area2 = cv2.contourArea(contour2)\n",
        "    intersection = np.logical_and(image1, image2)\n",
        "    contours, hierarchy = cv2.findContours(intersection.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return 0\n",
        "    common_area = cv2.contourArea(contours[0])\n",
        "    IoU = common_area/(area1+area2-common_area)\n",
        "    # Use the logical AND operation on the two images\n",
        "    # Since the two images had bitwise and applied to it,\n",
        "    # there should be a '1' or 'True' where there was intersection\n",
        "    # and a '0' or 'False' where it didnt intersect\n",
        "    # Check if there was a '1' in the intersection\n",
        "    return IoU\n",
        "\n",
        "\n",
        "def truePositive(predicted_box, true_box):\n",
        "    sum_IoU = 0\n",
        "    hit_count = 0\n",
        "    for conpred in predicted_box:\n",
        "      hit = 0\n",
        "      for contrue in true_box:\n",
        "        IoU = calculateIoU(conpred, contrue)\n",
        "        if IoU>0.6:\n",
        "          hit =  1\n",
        "          sum_IoU = sum_IoU+IoU\n",
        "      if hit == 1:\n",
        "        hit_count = hit_count + 1\n",
        "    if hit_count == 0:\n",
        "      return 0, None\n",
        "    ave_IoU = sum_IoU/hit_count    \n",
        "    return hit_count, ave_IoU\n",
        "\n",
        "def collect_annotation(dataframe):\n",
        "  true_box = []\n",
        "  for i in range(len(dataframe)):\n",
        "    rec1 = dataframe.iloc[i, :]\n",
        "    contour = np.array([[rec1.X1,rec1.Y1],[rec1.X2,rec1.Y2],[rec1.X3,rec1.Y3], [rec1.X4,rec1.Y4]], dtype=np.int32)\n",
        "    true_box.append(contour)\n",
        "  return true_box\n",
        "\n",
        "\n",
        "def collect_predicted(result):\n",
        "  Object, Mask = result\n",
        "  useful_index = []\n",
        "  for i in range(len(Object)):\n",
        "    score = Object[i]\n",
        "    if score > 0.6:\n",
        "      useful_index.append(i)\n",
        "\n",
        "  predicted_box = []\n",
        "  predicted_contour = []\n",
        "  for index in useful_index:\n",
        "    mg = Mask[index].cpu().numpy().astype(np.uint8)\n",
        "    contours, hierarchy = cv2.findContours(mg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt = contours[0]\n",
        "    rect = cv2.minAreaRect(cnt)\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.int0(box)\n",
        "    predicted_box.append(box)\n",
        "    predicted_contour.append(cnt)\n",
        "  return predicted_box, predicted_contour"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqU_ti1DMASm",
        "outputId": "11a5d493-e3ae-49ad-fa5c-633599847c01"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 108 ms (started: 2022-05-23 10:03:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Color'] = test_df['Color'].str.strip()\n",
        "image_name = test_df.loc[:, 'Image Filename'].unique() # get unique item in one column \n",
        "img_address_base = '/content/drive/MyDrive/barcode/Ananya.zip (Unzipped Files)/'\n",
        "misimage = []\n",
        "\n",
        "sum_hitR = 0\n",
        "sum_hitG = 0\n",
        "sum_hitB = 0\n",
        "\n",
        "pred_total = 0\n",
        "\n",
        "sum_R = 0\n",
        "sum_G = 0\n",
        "sum_B = 0\n",
        "for i in tqdm(range(len(image_name))):\n",
        "  df2 = df[df.loc[:, 'Image Filename']==image_name[i]] # choose data of one image \n",
        "  imgAddress = img_address_base + image_name[i] + '.jpg'  \n",
        "  img = cv2.imread(imgAddress)\n",
        "  output = predictor(img)\n",
        "  result = (output[\"instances\"].scores, output[\"instances\"].pred_masks)\n",
        "  predicted_box, predicted_contour = collect_predicted(result)\n",
        "  dfR = df2[df2.loc[:, 'Color'] == 'R']\n",
        "  dfG = df2[df2.loc[:, 'Color'] == 'G']\n",
        "  dfB = df2[df2.loc[:, 'Color'] == 'B']\n",
        "  true_box = collect_annotation(df2)\n",
        "  true_boxR = collect_annotation(dfR)\n",
        "  true_boxG = collect_annotation(dfG)\n",
        "  true_boxB = collect_annotation(dfB)\n",
        "  #hit, IoU = truePositive(predicted_box, true_box)\n",
        "  hitR, IoR = truePositive(predicted_box, true_boxR)\n",
        "  hitG, IoG = truePositive(predicted_box, true_boxG)\n",
        "  hitB, IoB = truePositive(predicted_box, true_boxB)\n",
        "\n",
        "  sum_hitR += hitR\n",
        "  sum_hitG += hitG\n",
        "  sum_hitB += hitB\n",
        "\n",
        "  sum_R += len(true_boxR) \n",
        "  sum_G += len(true_boxG) \n",
        "  sum_B += len(true_boxB) \n",
        "\n",
        "  pred_total += len(predicted_box)\n",
        "\n",
        "  sum_hit = hitR + hitB + hitG\n",
        "  sum_all = len(true_boxR)  + len(true_boxG) + len(true_boxB) \n",
        "  if sum_hit!=sum_all:\n",
        "    img = cv2.imread(imgAddress)\n",
        "    cv2.drawContours(img, predicted_box, -1 ,(0,255,0),2) # predicted result is green\n",
        "    cv2.drawContours(img, true_box, -1, (255,0,0), 2) # annotated result is blue \n",
        "    cv2.drawContours(img, predicted_contour, -1,(0,0,255),2) # the predicted contour is red\n",
        "    cv2_imshow(img)\n",
        "    print(f'number of R mishit is {len(true_boxR) - hitR}')\n",
        "    print(f'number of G mishit is {len(true_boxG) - hitG}')\n",
        "    print(f'number of B mishit is {len(true_boxB) - hitB}')"
      ],
      "metadata": {
        "id": "W-MIX8GjLRyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The accuracy of the algorithm is\n",
        "(sum_hitR + sum_hitG + sum_hitB)/(sum_R + sum_G + sum_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4jtvX_FQMuC",
        "outputId": "f12afb7f-774c-45db-987a-7a3dd338a1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9124087591240876"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.91 ms (started: 2022-05-23 04:50:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TP_all = sum_hitR + sum_hitG + sum_hitB\n",
        "TP_R = sum_hitR\n",
        "TP_G = sum_hitG\n",
        "TP_B = sum_hitB\n",
        "\n",
        "FN_all = sum_R + sum_G + sum_B - sum_hitR - sum_hitG - sum_hitB \n",
        "FN_R = sum_R - sum_hitR\n",
        "FN_G = sum_G - sum_hitG\n",
        "FN_B = sum_B - sum_hitB\n",
        "\n",
        "#since for a mis predicted, it can not be count into R or G or B. So we just assume all three of them get an average false Positive \n",
        "FP = pred_total - sum_hitR - sum_hitG - sum_hitB \n",
        "\n",
        "# TN can not be calcuated \n",
        "\n",
        "F1_all = 2*TP_all/(2*TP_all+FN_all+FP)\n",
        "F1_R = 2*TP_R/(2*TP_R+FN_R+FP/3)\n",
        "F1_G = 2*TP_G/(2*TP_G+FN_G+FP/3)\n",
        "F1_B = 2*TP_B/(2*TP_B+FN_B+FP/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg1667KoWubP",
        "outputId": "26501161-4346-4aff-a74a-fba1239572ce"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.49 ms (started: 2022-05-23 10:05:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Report for Detectron 2 model with Swin-T_R_50_FPN_3x')\n",
        "print(f'for all data TP is {TP_all}, FN is {FN_all}, FP is {FP}, TN can not be calculated, the F1 score is {F1_all:.2f}')\n",
        "print(f'for R data TP is {TP_R}, FN is {FN_R}, FP is {FP}, TN can not be calculated, the F1 score is {F1_R:.2f}')\n",
        "print(f'for G data TP is {TP_G}, FN is {FN_G}, FP is {FP}, TN can not be calculated, the F1 score is {F1_G:.2f}')\n",
        "print(f'for B data TP is {TP_B}, FN is {FN_B}, FP is {FP}, TN can not be calculated, the F1 score is {F1_B:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOjz0pBxbJNR",
        "outputId": "a8dcf85f-c6c0-45df-b9f4-0ace9abc3f5e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report for Detectron 2 model with mask_rcnn_R_50_FPN_3x\n",
            "for all data TP is 123, FN is 14, FP is 13, TN can not be calculated, the F1 score is 0.90\n",
            "for R data TP is 77, FN is 2, FP is 13, TN can not be calculated, the F1 score is 0.96\n",
            "for G data TP is 34, FN is 3, FP is 13, TN can not be calculated, the F1 score is 0.90\n",
            "for B data TP is 12, FN is 9, FP is 13, TN can not be calculated, the F1 score is 0.64\n",
            "time: 3.76 ms (started: 2022-05-23 10:05:13 +00:00)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Detectron2BarcodeIdentificationPlus.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQluS9lIlyvzgI32QlXIdl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}